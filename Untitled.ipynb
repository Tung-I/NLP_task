{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (BertConfig, BertForSequenceClassification, BertTokenizer,\n",
    "                          XLMConfig, XLMForSequenceClassification, XLMTokenizer,\n",
    "                          DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer,\n",
    "                          XLNetConfig,XLNetForSequenceClassification,XLNetTokenizer,\n",
    "                          RobertaConfig,RobertaForSequenceClassification,RobertaTokenizer\n",
    "                          )\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from box import Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/tony/NLP_task/task1/train.tsv',delimiter='\\t',header=None,names=['ids','label','alpha','sentence'])\n",
    "val = pd.read_csv('/home/tony/NLP_task/task1/val.tsv',delimiter='\\t',header=None,names=['ids','label','alpha','sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Yet when she and her husband put the house up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8632</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>We will compare Wyndham Destinations to relate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3699</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>With the appropriate safeguards, controls, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7543</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Thomas Cook had a rescue deal in place with in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9266</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>HomeTrading for BeginnersMarket AnalysisThe St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ids  label alpha                                           sentence\n",
       "0   703      0     a  Yet when she and her husband put the house up ...\n",
       "1  8632      0     a  We will compare Wyndham Destinations to relate...\n",
       "2  3699      0     a  With the appropriate safeguards, controls, and...\n",
       "3  7543      0     a  Thomas Cook had a rescue deal in place with in...\n",
       "4  9266      0     a  HomeTrading for BeginnersMarket AnalysisThe St..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents, train_labels = train.sentence.values, train.label.values\n",
    "val_sents, val_labels = val.sentence.values, val.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0512 21:45:16.900147 139874644301568 tokenization_utils.py:1011] loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/tony/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer_class = getattr(transformers, 'XLNetTokenizer')\n",
    "tokenizer = tokenizer_class.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_tokenize(sentences, tokenizer, MAX_LEN=128):\n",
    "    ids, attention_masks = [],[]\n",
    "    for sent in sentences:\n",
    "        encoded_sent = tokenizer.encode_plus(str(sent), add_special_tokens=True, max_length=MAX_LEN, \n",
    "                                             pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n",
    "        ids.append(encoded_sent['input_ids'])\n",
    "        attention_masks.append(encoded_sent['attention_mask'])\n",
    "    ids = torch.cat(ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    return ids, attention_masks\n",
    "\n",
    "def model_and_tokenizer(model_type, pretrain_weight):\n",
    "    MODEL_CLASSES = {\n",
    "        'bert': (BertForSequenceClassification, BertTokenizer),\n",
    "        'xlm': (XLMForSequenceClassification, XLMTokenizer),\n",
    "        'xlnet': (XLNetForSequenceClassification, XLNetTokenizer),\n",
    "        'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer),\n",
    "        'robetra': (RobertaForSequenceClassification, RobertaTokenizer)\n",
    "    }\n",
    "    model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "    model = model_class.from_pretrained(\n",
    "        pretrain_weight,\n",
    "        num_labels = 2,\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrain_weight, do_lower_case=True)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0512 20:25:57.541467 139874644301568 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/tony/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6\n",
      "I0512 20:25:57.542689 139874644301568 configuration_utils.py:321] Model config XLNetConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLNetLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mem_len\": null,\n",
      "  \"model_type\": \"xlnet\",\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"pad_token_id\": 5,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 250\n",
      "    }\n",
      "  },\n",
      "  \"untie_r\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "I0512 20:25:57.567656 139874644301568 modeling_utils.py:617] loading weights file https://cdn.huggingface.co/xlnet-base-cased-pytorch_model.bin from cache at /home/tony/.cache/torch/transformers/33d6135fea0154c088449506a4c5f9553cb59b6fd040138417a7033af64bb8f9.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac\n",
      "I0512 20:25:59.036801 139874644301568 modeling_utils.py:708] Weights of XLNetForSequenceClassification not initialized from pretrained model: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "I0512 20:25:59.037230 139874644301568 modeling_utils.py:714] Weights from pretrained model not used in XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "I0512 20:25:59.976103 139874644301568 tokenization_utils.py:1011] loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/tony/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = model_and_tokenizer('xlnet', 'xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_masks = sent_tokenize(train_sents,tokenizer)\n",
    "val_inputs, val_masks = sent_tokenize(val_sents,tokenizer)\n",
    "train_labels =torch.tensor(train_labels).to(torch.int64)\n",
    "val_labels =torch.tensor(val_labels).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8669, 128])\n",
      "torch.Size([8669, 128])\n",
      "torch.Size([8669])\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs.size())\n",
    "print(train_masks.size())\n",
    "print(train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = iter(train_dataloader)\n",
    "batch = next(iterator)\n",
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_input_ids,b_mask,b_label = tuple(t for t in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(b_input_ids.size())\n",
    "print(b_mask.size())\n",
    "print(b_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
